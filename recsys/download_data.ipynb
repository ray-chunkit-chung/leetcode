{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 08:44:19.597044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-24 08:44:19.597079: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-24 08:44:24.324233: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 5.64 MiB (download: 5.64 MiB, generated: 308.42 MiB, total: 314.06 MiB) to /root/tensorflow_datasets/movielens/1m-ratings/0.1.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474905d38db44a1aa424655e6dacca15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc5788e10004d889cb4e9859d261d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3814b8553d134d9e94f202e126cbfd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "DATA_DIR = \"./local\"\n",
    "\n",
    "data = tfds.load(\"movielens/1m-ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bucketized_user_age movie_genres movie_id                      movie_title  \\\n",
      "0                 35.0       [0, 7]  b'3107'              b'Backdraft (1991)'   \n",
      "1                 25.0          [7]  b'2114'         b'Outsiders, The (1983)'   \n",
      "2                 18.0      [4, 15]   b'256'                 b'Junior (1994)'   \n",
      "3                 18.0      [0, 10]  b'1389'               b'Jaws 3-D (1983)'   \n",
      "4                 18.0          [0]  b'3635'  b'Spy Who Loved Me, The (1977)'   \n",
      "\n",
      "    timestamp  user_gender  user_id  user_occupation_label  \\\n",
      "0   977432193         True   b'130'                     18   \n",
      "1   965932967        False  b'3829'                      0   \n",
      "2  1012103552        False  b'1265'                     21   \n",
      "3   972004605         True  b'2896'                     14   \n",
      "4   961180111         True  b'5264'                     17   \n",
      "\n",
      "      user_occupation_text  user_rating user_zip_code  \n",
      "0   b'technician/engineer'          5.0      b'50021'  \n",
      "1     b'academic/educator'          4.0      b'22307'  \n",
      "2                b'writer'          1.0      b'49321'  \n",
      "3       b'sales/marketing'          5.0      b'60073'  \n",
      "4  b'college/grad student'          4.0      b'15217'  \n"
     ]
    }
   ],
   "source": [
    "df = tfds.as_dataframe(data[\"train\"])\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this tutorial, let us only use the bare minimum: user_id, movie_id,\n",
    "# and user_rating since very often this is the only data we have\n",
    "filtered_data = (\n",
    "    df\n",
    "    .filter([\"timestamp\", \"user_id\", \"movie_id\", \"user_rating\"])\n",
    "    .sort_values(\"timestamp\")\n",
    "    .astype({\"user_id\": int, \"movie_id\": int, \"user_rating\": int}) # nicer types\n",
    "    .drop(columns=[\"timestamp\"]) # don't need the timestamp anymore\n",
    ")\n",
    "\n",
    "# We will also keep the timestamp to conduct a temporal train-test split since \n",
    "#  this resembles how we train in real life: we train now, but we want the model\n",
    "# to work well tomorrow. So we should evaluate the model quality like this as well.\n",
    "train = filtered_data.iloc[:900000] # chronologically first 90% of the dataset\n",
    "test = filtered_data.iloc[900000:]  # chronologically last 10% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# cold start problem exists, meaning that some users or movies are only \n",
    "# present in the test set, but not in the training set.\n",
    "print(train.query(\"user_id == 1\").shape[0])\n",
    "print(test.query(\"user_id == 1\").shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for later in the train.py script\n",
    "\n",
    "import os\n",
    "if os.path.isdir(DATA_DIR) == False:\n",
    "    os.mkdir(DATA_DIR)\n",
    "\n",
    "train.to_csv(f\"{DATA_DIR}/train.csv\", index=False)\n",
    "test.to_csv(f\"{DATA_DIR}/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
